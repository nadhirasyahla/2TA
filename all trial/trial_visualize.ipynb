{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing transformation\n",
    "preprocess_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 pixels \n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(\n",
    "        # Normalization mean for ImageNet that already computed\n",
    "        mean=[0.485, 0.456, 0.406],  #mean  represents avg color intensity\n",
    "        # Normalization std for ImageNet that already computed\n",
    "        std=[0.229, 0.224, 0.225]    #std represent how much color itensity from mean\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentaion for training\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0,406],\n",
    "        std=[0.229, 0.224, 0.255]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert('RGB')  # Convert to RGB\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Load your images and labels\n",
    "folder_path = r'C:\\Users\\user\\Documents\\!TA\\!TA\\cornealtopography\\Independent Test Set\\Independent Test Set\\Keratoconus\\case1'\n",
    "images = load_images_from_folder(folder_path)\n",
    "labels = [0, 1, 0, 1, ...]  # Example labels, replace with your actual labels\n",
    "\n",
    "# Create dataset with the augmentation transform\n",
    "train_dataset = CustomImageDataset(images, labels, transform=augment_transform)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Visualize some augmented images\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mvisualize_augmented_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mvisualize_augmented_images\u001b[1;34m(dataset, num_images, figsize)\u001b[0m\n\u001b[0;32m      2\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, num_images, figsize\u001b[38;5;241m=\u001b[39mfigsize)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_images):\n\u001b[1;32m----> 4\u001b[0m     image, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Convert to HWC format\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     image \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m*\u001b[39m [\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m]  \u001b[38;5;66;03m# Unnormalize\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 14\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\transforms\\_functional_tensor.py:926\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    925\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_augmented_images(dataset, num_images=5, figsize=(15, 5)):\n",
    "    fig, axs = plt.subplots(1, num_images, figsize=figsize)\n",
    "    for i in range(num_images):\n",
    "        image, _ = dataset[i]\n",
    "        image = image.permute(1, 2, 0).numpy()  # Convert to HWC format\n",
    "        image = image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]  # Unnormalize\n",
    "        image = np.clip(image, 0, 1)  # Ensure the image values are between 0 and 1\n",
    "\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some augmented images\n",
    "visualize_augmented_images(train_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
