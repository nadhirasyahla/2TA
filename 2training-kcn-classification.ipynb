{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b30154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:06.993629Z",
     "iopub.status.busy": "2025-06-27T14:50:06.993410Z",
     "iopub.status.idle": "2025-06-27T14:50:15.001913Z",
     "shell.execute_reply": "2025-06-27T14:50:15.001180Z"
    },
    "id": "x5ee94tk9wcf",
    "outputId": "fa8453f8-e4a0-4e0c-fa41-24aeba9ae9fc",
    "papermill": {
     "duration": 8.014289,
     "end_time": "2025-06-27T14:50:15.003503",
     "exception": false,
     "start_time": "2025-06-27T14:50:06.989214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, BatchSampler, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.models import VGG16_Weights\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f079268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.011001Z",
     "iopub.status.busy": "2025-06-27T14:50:15.010656Z",
     "iopub.status.idle": "2025-06-27T14:50:15.064038Z",
     "shell.execute_reply": "2025-06-27T14:50:15.063018Z"
    },
    "papermill": {
     "duration": 0.058304,
     "end_time": "2025-06-27T14:50:15.065406",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.007102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955bdea",
   "metadata": {
    "papermill": {
     "duration": 0.002741,
     "end_time": "2025-06-27T14:50:15.071367",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.068626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5374acdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.077878Z",
     "iopub.status.busy": "2025-06-27T14:50:15.077660Z",
     "iopub.status.idle": "2025-06-27T14:50:15.084770Z",
     "shell.execute_reply": "2025-06-27T14:50:15.084181Z"
    },
    "papermill": {
     "duration": 0.011735,
     "end_time": "2025-06-27T14:50:15.085970",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.074235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform if transform else get_default_transform()\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.label_map = {'KCN':0, 'NOR':1, 'SUSP':2}\n",
    "\n",
    "        #class loop\n",
    "        for class_name in os.listdir(root_dir):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "            for case_name in os.listdir(class_path):\n",
    "                case_path = os.path.join(class_path, case_name)\n",
    "                if os.path.isdir(case_path):\n",
    "                    #pick prefix\n",
    "                    sample_files = os.listdir(case_path)\n",
    "                    if sample_files:\n",
    "                        prefix = sample_files[0].split('_')[0] \n",
    "                        case_number = sample_files[0].split('_')[1]\n",
    "                        case_prefix = f\"{prefix}_{case_number}\"\n",
    "                        self.samples.append((case_path, case_prefix, prefix))\n",
    "                        self.labels.append(self.label_map[prefix])\n",
    "        self.labels = np.array(self.labels)\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_path, case_prefix, prefix = self.samples[idx]\n",
    "\n",
    "        #akhiran nama file\n",
    "        feature_suffixes = [\n",
    "            \"_CT_A.jpg\", \"_EC_A.jpg\", \"_EC_P.jpg\", \"_Elv_A.jpg\",\"_Elv_P.jpg\", \"_Sag_A.jpg\", \"_Sag_P.jpg\"\n",
    "        ]\n",
    "\n",
    "        feature_images = []\n",
    "        for suffix in feature_suffixes :\n",
    "            filename = f\"{case_prefix}{suffix}\"\n",
    "            img_path = os.path.join(case_path, filename)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = self.transform(img)\n",
    "            feature_images.append(img)\n",
    "\n",
    "        #shape : (7, 3, H, W)\n",
    "        stacked = torch.stack(feature_images, dim=0)\n",
    "        label = self.label_map[prefix]\n",
    "        return stacked, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14785beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.092637Z",
     "iopub.status.busy": "2025-06-27T14:50:15.092432Z",
     "iopub.status.idle": "2025-06-27T14:50:15.095791Z",
     "shell.execute_reply": "2025-06-27T14:50:15.095195Z"
    },
    "papermill": {
     "duration": 0.007929,
     "end_time": "2025-06-27T14:50:15.096933",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.089004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_default_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2379f8b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.103328Z",
     "iopub.status.busy": "2025-06-27T14:50:15.103112Z",
     "iopub.status.idle": "2025-06-27T14:50:15.106559Z",
     "shell.execute_reply": "2025-06-27T14:50:15.105942Z"
    },
    "papermill": {
     "duration": 0.007809,
     "end_time": "2025-06-27T14:50:15.107653",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.099844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, transform=None):\n",
    "    #create and return teh dataset instance\n",
    "    try :\n",
    "        dataset = MultiInputDataset(data_dir, transform)\n",
    "        print(f'Dataset loaded succesfully with {len(dataset)} samples')\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f'Error loading dataset : {str(e)}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8dbb93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.114040Z",
     "iopub.status.busy": "2025-06-27T14:50:15.113841Z",
     "iopub.status.idle": "2025-06-27T14:50:15.117582Z",
     "shell.execute_reply": "2025-06-27T14:50:15.116973Z"
    },
    "papermill": {
     "duration": 0.00807,
     "end_time": "2025-06-27T14:50:15.118649",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.110579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_train_val_split(dataset, val_size=0.2, random_state=42):\n",
    "    #splitting dataset with statification\n",
    "    try :\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            range(len(dataset)),\n",
    "            test_size = val_size,\n",
    "            stratify = dataset.labels,\n",
    "            random_state = random_state\n",
    "        )\n",
    "        print(f'Split created : {len(train_idx)} training samples ; {len(val_idx)} validation samples')\n",
    "        return train_idx, val_idx\n",
    "    except Exception as e:\n",
    "        print(f'Error Splitting : {str(e)}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda3cc81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.124922Z",
     "iopub.status.busy": "2025-06-27T14:50:15.124731Z",
     "iopub.status.idle": "2025-06-27T14:50:15.128502Z",
     "shell.execute_reply": "2025-06-27T14:50:15.127880Z"
    },
    "papermill": {
     "duration": 0.008093,
     "end_time": "2025-06-27T14:50:15.129577",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.121484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, val_dataset, batch_size=8, num_workers=2):\n",
    "    #create and return train and val dataloaders\n",
    "    try :\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True,\n",
    "            num_workers = num_workers,\n",
    "            pin_memory = True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = False,\n",
    "            num_workers = num_workers,\n",
    "            pin_memory = True\n",
    "        )\n",
    "        print(f'DataLoaders created with batch size {batch_size}')\n",
    "        return train_loader, val_loader\n",
    "    except Exception as e:\n",
    "        print(f'Error creating DataLoaders : {str(e)}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3268154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.135903Z",
     "iopub.status.busy": "2025-06-27T14:50:15.135700Z",
     "iopub.status.idle": "2025-06-27T14:50:15.138553Z",
     "shell.execute_reply": "2025-06-27T14:50:15.137942Z"
    },
    "papermill": {
     "duration": 0.007244,
     "end_time": "2025-06-27T14:50:15.139687",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.132443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def prepare_dataloaders(data_dir, batch_size=8, test_size=0.2, random_state=42):\n",
    "\n",
    "#     print(f'Loading dara from : {os.path.abspath(data_dir)}')\n",
    "#     transform = get_default_transform()\n",
    "#     full_dataset = MultiInputDataset(root_dir = data_dir, transform=transform)\n",
    "#     print(f\"Dataset created with {len(full_dataset)} samples\")\n",
    "#     if len(full_dataset) == 0:\n",
    "#         print(f'WARNING : Dataset is empty!')\n",
    "#         return None, None\n",
    "\n",
    "#     train_idx, val_idx = train_test_split(\n",
    "#         list(range(len(full_dataset))),\n",
    "#         test_size=test_size,\n",
    "#         random_state=random_state,\n",
    "#         shuffle=True\n",
    "#     )\n",
    "\n",
    "#     train_dataset = Subset(full_dataset, train_idx)\n",
    "#     val_dataset = Subset(full_dataset, val_idx)\n",
    "\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "#     return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b6d707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.146046Z",
     "iopub.status.busy": "2025-06-27T14:50:15.145856Z",
     "iopub.status.idle": "2025-06-27T14:50:15.149384Z",
     "shell.execute_reply": "2025-06-27T14:50:15.148633Z"
    },
    "papermill": {
     "duration": 0.007853,
     "end_time": "2025-06-27T14:50:15.150477",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.142624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_sample_batch(loader):\n",
    "    try :\n",
    "        images, labels = next(iter(loader))\n",
    "        print(f\"Batch image shape : \", images.shape)\n",
    "        print(f\"Labels : \", labels)\n",
    "    except Exception as e:\n",
    "        print(f'Error in testing sample batch : {str(e)}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67328b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.156767Z",
     "iopub.status.busy": "2025-06-27T14:50:15.156575Z",
     "iopub.status.idle": "2025-06-27T14:50:15.159095Z",
     "shell.execute_reply": "2025-06-27T14:50:15.158538Z"
    },
    "papermill": {
     "duration": 0.006828,
     "end_time": "2025-06-27T14:50:15.160188",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.153360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = \"/kaggle/input/cornealtopography/Train_Validation sets/Train_Validation sets\"\n",
    "\n",
    "# print(\"Folders : \", os.listdir(data_dir))\n",
    "# for class_name in os.listdir(data_dir):\n",
    "#     class_path = os.path.join(data_dir, class_name)\n",
    "#     print(f\"{class_name} -> {len(os.listdir(class_path))} case\")\n",
    "\n",
    "# train_loader, val_loader = prepare_dataloaders(data_dir, batch_size=8)\n",
    "# test_sample_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c154d9",
   "metadata": {
    "papermill": {
     "duration": 0.00263,
     "end_time": "2025-06-27T14:50:15.165644",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.163014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # MODEL SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42bc6701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.171887Z",
     "iopub.status.busy": "2025-06-27T14:50:15.171689Z",
     "iopub.status.idle": "2025-06-27T14:50:15.175507Z",
     "shell.execute_reply": "2025-06-27T14:50:15.174909Z"
    },
    "papermill": {
     "duration": 0.008179,
     "end_time": "2025-06-27T14:50:15.176676",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.168497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_vgg16(num_classes = 3, device = None):\n",
    "\n",
    "    print(f'Preparing VGG16 for {num_classes} classes...')\n",
    "    vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "    for param in vgg16.parameters():\n",
    "        param.requires_grad = False\n",
    "    vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, num_classes)\n",
    "    for param in vgg16.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    if device is not None:\n",
    "        vgg16 = vgg16.to(device)\n",
    "    print(f'Model ready!')\n",
    "\n",
    "    return vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8059c1aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.183104Z",
     "iopub.status.busy": "2025-06-27T14:50:15.182913Z",
     "iopub.status.idle": "2025-06-27T14:50:15.187270Z",
     "shell.execute_reply": "2025-06-27T14:50:15.186718Z"
    },
    "papermill": {
     "duration": 0.008808,
     "end_time": "2025-06-27T14:50:15.188410",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.179602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main() : \n",
    "    data_dir = \"/kaggle/input/cornealtopography/Train_Validation sets/Train_Validation sets\"\n",
    "    try :\n",
    "        print(\"Folders : \", os.listdir(data_dir))\n",
    "        for class_name in os.listdir(data_dir):\n",
    "            class_path = os.path.join(data_dir, class_name)\n",
    "            print(f\"{class_name} -> {len(os.listdir(class_path))} case\")\n",
    "\n",
    "        #data preparation\n",
    "        dataset = load_dataset(data_dir)\n",
    "        train_idx, val_idx = create_train_val_split(dataset)\n",
    "\n",
    "        train_dataset = Subset(dataset, train_idx)\n",
    "        val_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader, val_loader = create_dataloaders(train_dataset, val_dataset)\n",
    "\n",
    "        test_sample_batch (train_loader)\n",
    "\n",
    "        #model setup\n",
    "        model = get_model_vgg16(num_classes = 3, device=device)\n",
    "        \n",
    "        return train_loader, val_loader, model\n",
    "\n",
    "    except Exception as e :\n",
    "        print(f'Error in main workflow : {str(e)}')\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9eb6687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:50:15.194860Z",
     "iopub.status.busy": "2025-06-27T14:50:15.194636Z",
     "iopub.status.idle": "2025-06-27T14:50:25.878402Z",
     "shell.execute_reply": "2025-06-27T14:50:25.877426Z"
    },
    "papermill": {
     "duration": 10.688384,
     "end_time": "2025-06-27T14:50:25.879696",
     "exception": false,
     "start_time": "2025-06-27T14:50:15.191312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders :  ['Keratoconus', 'Normal', 'Suspect']\n",
      "Keratoconus -> 150 case\n",
      "Normal -> 150 case\n",
      "Suspect -> 123 case\n",
      "Dataset loaded succesfully with 423 samples\n",
      "Split created : 338 training samples ; 85 validation samples\n",
      "DataLoaders created with batch size 8\n",
      "Batch image shape :  torch.Size([8, 7, 3, 224, 224])\n",
      "Labels :  tensor([0, 0, 2, 1, 0, 1, 0, 2])\n",
      "Preparing VGG16 for 3 classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 243MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    traind_loader, val_loader, model = main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6505884,
     "sourceId": 10508636,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6529307,
     "sourceId": 11419113,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6529314,
     "sourceId": 11545904,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 235859085,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.726234,
   "end_time": "2025-06-27T14:50:28.227387",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-27T14:50:04.501153",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
