{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the DataLoader objects\n",
    "with open(r\"C:\\Users\\user\\Documents\\!TA\\!TA\\all trial\\train_loader.pkl\", \"rb\") as f:\n",
    "    train_loader = pickle.load(f)\n",
    "with open(r\"C:\\Users\\user\\Documents\\!TA\\!TA\\all trial\\valid_loader.pkl\", \"rb\") as f:\n",
    "    valid_loader = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader: 74 batches\n",
      "Valid Loader: 19 batches\n"
     ]
    }
   ],
   "source": [
    "#Confirm the DataLoaders are loaded\n",
    "print(f\"Train Loader: {len(train_loader)} batches\")\n",
    "print(f\"Valid Loader: {len(valid_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Check device availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet18 model\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for 3 output classes\n",
    "resnet18.fc = nn.Linear(in_features=resnet18.fc.in_features, out_features=3)  # 3 classes: Keratoconus, Normal, Suspect\n",
    "\n",
    "# Move the model to the appropriate device (GPU/CPU)\n",
    "resnet18 = resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight: requires_grad=False\n",
      "bn1.weight: requires_grad=False\n",
      "bn1.bias: requires_grad=False\n",
      "layer1.0.conv1.weight: requires_grad=False\n",
      "layer1.0.bn1.weight: requires_grad=False\n",
      "layer1.0.bn1.bias: requires_grad=False\n",
      "layer1.0.conv2.weight: requires_grad=False\n",
      "layer1.0.bn2.weight: requires_grad=False\n",
      "layer1.0.bn2.bias: requires_grad=False\n",
      "layer1.1.conv1.weight: requires_grad=False\n",
      "layer1.1.bn1.weight: requires_grad=False\n",
      "layer1.1.bn1.bias: requires_grad=False\n",
      "layer1.1.conv2.weight: requires_grad=False\n",
      "layer1.1.bn2.weight: requires_grad=False\n",
      "layer1.1.bn2.bias: requires_grad=False\n",
      "layer2.0.conv1.weight: requires_grad=False\n",
      "layer2.0.bn1.weight: requires_grad=False\n",
      "layer2.0.bn1.bias: requires_grad=False\n",
      "layer2.0.conv2.weight: requires_grad=False\n",
      "layer2.0.bn2.weight: requires_grad=False\n",
      "layer2.0.bn2.bias: requires_grad=False\n",
      "layer2.0.downsample.0.weight: requires_grad=False\n",
      "layer2.0.downsample.1.weight: requires_grad=False\n",
      "layer2.0.downsample.1.bias: requires_grad=False\n",
      "layer2.1.conv1.weight: requires_grad=False\n",
      "layer2.1.bn1.weight: requires_grad=False\n",
      "layer2.1.bn1.bias: requires_grad=False\n",
      "layer2.1.conv2.weight: requires_grad=False\n",
      "layer2.1.bn2.weight: requires_grad=False\n",
      "layer2.1.bn2.bias: requires_grad=False\n",
      "layer3.0.conv1.weight: requires_grad=False\n",
      "layer3.0.bn1.weight: requires_grad=False\n",
      "layer3.0.bn1.bias: requires_grad=False\n",
      "layer3.0.conv2.weight: requires_grad=False\n",
      "layer3.0.bn2.weight: requires_grad=False\n",
      "layer3.0.bn2.bias: requires_grad=False\n",
      "layer3.0.downsample.0.weight: requires_grad=False\n",
      "layer3.0.downsample.1.weight: requires_grad=False\n",
      "layer3.0.downsample.1.bias: requires_grad=False\n",
      "layer3.1.conv1.weight: requires_grad=False\n",
      "layer3.1.bn1.weight: requires_grad=False\n",
      "layer3.1.bn1.bias: requires_grad=False\n",
      "layer3.1.conv2.weight: requires_grad=False\n",
      "layer3.1.bn2.weight: requires_grad=False\n",
      "layer3.1.bn2.bias: requires_grad=False\n",
      "layer4.0.conv1.weight: requires_grad=False\n",
      "layer4.0.bn1.weight: requires_grad=False\n",
      "layer4.0.bn1.bias: requires_grad=False\n",
      "layer4.0.conv2.weight: requires_grad=False\n",
      "layer4.0.bn2.weight: requires_grad=False\n",
      "layer4.0.bn2.bias: requires_grad=False\n",
      "layer4.0.downsample.0.weight: requires_grad=False\n",
      "layer4.0.downsample.1.weight: requires_grad=False\n",
      "layer4.0.downsample.1.bias: requires_grad=False\n",
      "layer4.1.conv1.weight: requires_grad=False\n",
      "layer4.1.bn1.weight: requires_grad=False\n",
      "layer4.1.bn1.bias: requires_grad=False\n",
      "layer4.1.conv2.weight: requires_grad=False\n",
      "layer4.1.bn2.weight: requires_grad=False\n",
      "layer4.1.bn2.bias: requires_grad=False\n",
      "fc.weight: requires_grad=True\n",
      "fc.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "# Freeze the feature extractor layers (everything except the final classifier layer)\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Unfreeze the final classifier layer to fine-tune it\n",
    "for param in resnet18.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Print the names of layers and whether they are trainable\n",
    "for name, param in resnet18.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(resnet18.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Reduce lr by 0.5 every 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early stopping criteria\n",
    "# best_accuracy = 0.0\n",
    "# patience = 3  # Stop after 3 epochs with no improvement\n",
    "# epochs_without_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training function\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=30):\n",
    "    # global best_accuracy, epochs_without_improvement\n",
    "    best_accuracy = 0.0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training loop\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        # Calculate train accuracy\n",
    "        train_accuracy = 100 * train_correct / total_train\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        valid_correct = 0\n",
    "        total_valid = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                valid_correct += (preds == labels).sum().item()\n",
    "                total_valid += labels.size(0)\n",
    "                \n",
    "        # Calculate validatin accuracy\n",
    "        valid_accuracy = 100 * valid_correct / total_valid\n",
    "\n",
    "        # Print stats for the epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Validation Accuracy: {valid_accuracy:.2f}%\")\n",
    "\n",
    "        # Save the model with the best validation accuracy\n",
    "        if valid_accuracy > best_accuracy:\n",
    "            best_accuracy = valid_accuracy\n",
    "            torch.save(model.state_dict(), \"best_resnet18_model.pth\")\n",
    "        #     epochs_without_improvement = 0\n",
    "        # else:\n",
    "        #     epochs_without_improvement += 1\n",
    "\n",
    "        # # Save checkpoints after every 5 epochs\n",
    "        # if (epoch + 1) % 5 == 0:\n",
    "        #     torch.save(model.state_dict(), f\"vgg16_epoch_{epoch+1}.pth\")\n",
    "\n",
    "        # # Stop training early if no improvement\n",
    "        # if epochs_without_improvement >= patience:\n",
    "        #     print(\"Early stopping triggered!\")\n",
    "        #     break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.8863, Train Accuracy: 57.47%, Validation Accuracy: 64.59%\n",
      "Epoch [2/30], Train Loss: 0.7577, Train Accuracy: 65.79%, Validation Accuracy: 63.07%\n",
      "Epoch [3/30], Train Loss: 0.7196, Train Accuracy: 67.02%, Validation Accuracy: 67.96%\n",
      "Epoch [4/30], Train Loss: 0.6859, Train Accuracy: 68.03%, Validation Accuracy: 68.47%\n",
      "Epoch [5/30], Train Loss: 0.6710, Train Accuracy: 69.72%, Validation Accuracy: 68.80%\n",
      "Epoch [6/30], Train Loss: 0.6464, Train Accuracy: 71.37%, Validation Accuracy: 69.65%\n",
      "Epoch [7/30], Train Loss: 0.6448, Train Accuracy: 71.07%, Validation Accuracy: 69.98%\n",
      "Epoch [8/30], Train Loss: 0.6219, Train Accuracy: 72.97%, Validation Accuracy: 70.83%\n",
      "Epoch [9/30], Train Loss: 0.6420, Train Accuracy: 70.86%, Validation Accuracy: 71.16%\n",
      "Epoch [10/30], Train Loss: 0.6249, Train Accuracy: 71.62%, Validation Accuracy: 72.18%\n",
      "Epoch [11/30], Train Loss: 0.6148, Train Accuracy: 72.42%, Validation Accuracy: 71.67%\n",
      "Epoch [12/30], Train Loss: 0.6192, Train Accuracy: 73.06%, Validation Accuracy: 71.84%\n",
      "Epoch [13/30], Train Loss: 0.6071, Train Accuracy: 73.27%, Validation Accuracy: 72.68%\n",
      "Epoch [14/30], Train Loss: 0.6104, Train Accuracy: 72.51%, Validation Accuracy: 71.84%\n",
      "Epoch [15/30], Train Loss: 0.5969, Train Accuracy: 73.10%, Validation Accuracy: 72.85%\n",
      "Epoch [16/30], Train Loss: 0.5973, Train Accuracy: 74.28%, Validation Accuracy: 71.33%\n",
      "Epoch [17/30], Train Loss: 0.6028, Train Accuracy: 73.78%, Validation Accuracy: 73.36%\n",
      "Epoch [18/30], Train Loss: 0.5929, Train Accuracy: 73.40%, Validation Accuracy: 72.68%\n",
      "Epoch [19/30], Train Loss: 0.6009, Train Accuracy: 74.07%, Validation Accuracy: 71.67%\n",
      "Epoch [20/30], Train Loss: 0.6024, Train Accuracy: 73.31%, Validation Accuracy: 71.50%\n",
      "Epoch [21/30], Train Loss: 0.6024, Train Accuracy: 73.02%, Validation Accuracy: 73.02%\n",
      "Epoch [22/30], Train Loss: 0.5875, Train Accuracy: 74.83%, Validation Accuracy: 72.68%\n",
      "Epoch [23/30], Train Loss: 0.5943, Train Accuracy: 74.28%, Validation Accuracy: 72.85%\n",
      "Epoch [24/30], Train Loss: 0.5929, Train Accuracy: 73.56%, Validation Accuracy: 73.02%\n",
      "Epoch [25/30], Train Loss: 0.5947, Train Accuracy: 74.75%, Validation Accuracy: 72.85%\n",
      "Epoch [26/30], Train Loss: 0.5917, Train Accuracy: 73.78%, Validation Accuracy: 72.85%\n",
      "Epoch [27/30], Train Loss: 0.5964, Train Accuracy: 73.18%, Validation Accuracy: 72.18%\n",
      "Epoch [28/30], Train Loss: 0.5875, Train Accuracy: 73.82%, Validation Accuracy: 72.85%\n",
      "Epoch [29/30], Train Loss: 0.5866, Train Accuracy: 74.79%, Validation Accuracy: 72.68%\n",
      "Epoch [30/30], Train Loss: 0.5982, Train Accuracy: 73.94%, Validation Accuracy: 73.02%\n",
      "Best Validation Accuracy: 73.36%\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "train_model(resnet18, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
