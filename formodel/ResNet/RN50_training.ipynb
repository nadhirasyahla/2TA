{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the DataLoader objects\n",
    "with open(r\"C:\\Users\\user\\Documents\\!TA\\!TA\\all trial\\train_loader.pkl\", \"rb\") as f:\n",
    "    train_loader = pickle.load(f)\n",
    "with open(r\"C:\\Users\\user\\Documents\\!TA\\!TA\\all trial\\valid_loader.pkl\", \"rb\") as f:\n",
    "    valid_loader = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader: 37 batches\n",
      "Valid Loader: 10 batches\n"
     ]
    }
   ],
   "source": [
    "#Confirm the DataLoaders are loaded\n",
    "print(f\"Train Loader: {len(train_loader)} batches\")\n",
    "print(f\"Valid Loader: {len(valid_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Check device availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet50resnet50 model\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for 3 output classes\n",
    "resnet50.fc = nn.Linear(in_features=resnet50.fc.in_features, out_features=3)  # 3 classes: Keratoconus, Normal, Suspect\n",
    "\n",
    "# Move the model to the appropriate device (GPU/CPU)\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight: requires_grad=False\n",
      "bn1.weight: requires_grad=False\n",
      "bn1.bias: requires_grad=False\n",
      "layer1.0.conv1.weight: requires_grad=False\n",
      "layer1.0.bn1.weight: requires_grad=False\n",
      "layer1.0.bn1.bias: requires_grad=False\n",
      "layer1.0.conv2.weight: requires_grad=False\n",
      "layer1.0.bn2.weight: requires_grad=False\n",
      "layer1.0.bn2.bias: requires_grad=False\n",
      "layer1.0.conv3.weight: requires_grad=False\n",
      "layer1.0.bn3.weight: requires_grad=False\n",
      "layer1.0.bn3.bias: requires_grad=False\n",
      "layer1.0.downsample.0.weight: requires_grad=False\n",
      "layer1.0.downsample.1.weight: requires_grad=False\n",
      "layer1.0.downsample.1.bias: requires_grad=False\n",
      "layer1.1.conv1.weight: requires_grad=False\n",
      "layer1.1.bn1.weight: requires_grad=False\n",
      "layer1.1.bn1.bias: requires_grad=False\n",
      "layer1.1.conv2.weight: requires_grad=False\n",
      "layer1.1.bn2.weight: requires_grad=False\n",
      "layer1.1.bn2.bias: requires_grad=False\n",
      "layer1.1.conv3.weight: requires_grad=False\n",
      "layer1.1.bn3.weight: requires_grad=False\n",
      "layer1.1.bn3.bias: requires_grad=False\n",
      "layer1.2.conv1.weight: requires_grad=False\n",
      "layer1.2.bn1.weight: requires_grad=False\n",
      "layer1.2.bn1.bias: requires_grad=False\n",
      "layer1.2.conv2.weight: requires_grad=False\n",
      "layer1.2.bn2.weight: requires_grad=False\n",
      "layer1.2.bn2.bias: requires_grad=False\n",
      "layer1.2.conv3.weight: requires_grad=False\n",
      "layer1.2.bn3.weight: requires_grad=False\n",
      "layer1.2.bn3.bias: requires_grad=False\n",
      "layer2.0.conv1.weight: requires_grad=False\n",
      "layer2.0.bn1.weight: requires_grad=False\n",
      "layer2.0.bn1.bias: requires_grad=False\n",
      "layer2.0.conv2.weight: requires_grad=False\n",
      "layer2.0.bn2.weight: requires_grad=False\n",
      "layer2.0.bn2.bias: requires_grad=False\n",
      "layer2.0.conv3.weight: requires_grad=False\n",
      "layer2.0.bn3.weight: requires_grad=False\n",
      "layer2.0.bn3.bias: requires_grad=False\n",
      "layer2.0.downsample.0.weight: requires_grad=False\n",
      "layer2.0.downsample.1.weight: requires_grad=False\n",
      "layer2.0.downsample.1.bias: requires_grad=False\n",
      "layer2.1.conv1.weight: requires_grad=False\n",
      "layer2.1.bn1.weight: requires_grad=False\n",
      "layer2.1.bn1.bias: requires_grad=False\n",
      "layer2.1.conv2.weight: requires_grad=False\n",
      "layer2.1.bn2.weight: requires_grad=False\n",
      "layer2.1.bn2.bias: requires_grad=False\n",
      "layer2.1.conv3.weight: requires_grad=False\n",
      "layer2.1.bn3.weight: requires_grad=False\n",
      "layer2.1.bn3.bias: requires_grad=False\n",
      "layer2.2.conv1.weight: requires_grad=False\n",
      "layer2.2.bn1.weight: requires_grad=False\n",
      "layer2.2.bn1.bias: requires_grad=False\n",
      "layer2.2.conv2.weight: requires_grad=False\n",
      "layer2.2.bn2.weight: requires_grad=False\n",
      "layer2.2.bn2.bias: requires_grad=False\n",
      "layer2.2.conv3.weight: requires_grad=False\n",
      "layer2.2.bn3.weight: requires_grad=False\n",
      "layer2.2.bn3.bias: requires_grad=False\n",
      "layer2.3.conv1.weight: requires_grad=False\n",
      "layer2.3.bn1.weight: requires_grad=False\n",
      "layer2.3.bn1.bias: requires_grad=False\n",
      "layer2.3.conv2.weight: requires_grad=False\n",
      "layer2.3.bn2.weight: requires_grad=False\n",
      "layer2.3.bn2.bias: requires_grad=False\n",
      "layer2.3.conv3.weight: requires_grad=False\n",
      "layer2.3.bn3.weight: requires_grad=False\n",
      "layer2.3.bn3.bias: requires_grad=False\n",
      "layer3.0.conv1.weight: requires_grad=False\n",
      "layer3.0.bn1.weight: requires_grad=False\n",
      "layer3.0.bn1.bias: requires_grad=False\n",
      "layer3.0.conv2.weight: requires_grad=False\n",
      "layer3.0.bn2.weight: requires_grad=False\n",
      "layer3.0.bn2.bias: requires_grad=False\n",
      "layer3.0.conv3.weight: requires_grad=False\n",
      "layer3.0.bn3.weight: requires_grad=False\n",
      "layer3.0.bn3.bias: requires_grad=False\n",
      "layer3.0.downsample.0.weight: requires_grad=False\n",
      "layer3.0.downsample.1.weight: requires_grad=False\n",
      "layer3.0.downsample.1.bias: requires_grad=False\n",
      "layer3.1.conv1.weight: requires_grad=False\n",
      "layer3.1.bn1.weight: requires_grad=False\n",
      "layer3.1.bn1.bias: requires_grad=False\n",
      "layer3.1.conv2.weight: requires_grad=False\n",
      "layer3.1.bn2.weight: requires_grad=False\n",
      "layer3.1.bn2.bias: requires_grad=False\n",
      "layer3.1.conv3.weight: requires_grad=False\n",
      "layer3.1.bn3.weight: requires_grad=False\n",
      "layer3.1.bn3.bias: requires_grad=False\n",
      "layer3.2.conv1.weight: requires_grad=False\n",
      "layer3.2.bn1.weight: requires_grad=False\n",
      "layer3.2.bn1.bias: requires_grad=False\n",
      "layer3.2.conv2.weight: requires_grad=False\n",
      "layer3.2.bn2.weight: requires_grad=False\n",
      "layer3.2.bn2.bias: requires_grad=False\n",
      "layer3.2.conv3.weight: requires_grad=False\n",
      "layer3.2.bn3.weight: requires_grad=False\n",
      "layer3.2.bn3.bias: requires_grad=False\n",
      "layer3.3.conv1.weight: requires_grad=False\n",
      "layer3.3.bn1.weight: requires_grad=False\n",
      "layer3.3.bn1.bias: requires_grad=False\n",
      "layer3.3.conv2.weight: requires_grad=False\n",
      "layer3.3.bn2.weight: requires_grad=False\n",
      "layer3.3.bn2.bias: requires_grad=False\n",
      "layer3.3.conv3.weight: requires_grad=False\n",
      "layer3.3.bn3.weight: requires_grad=False\n",
      "layer3.3.bn3.bias: requires_grad=False\n",
      "layer3.4.conv1.weight: requires_grad=False\n",
      "layer3.4.bn1.weight: requires_grad=False\n",
      "layer3.4.bn1.bias: requires_grad=False\n",
      "layer3.4.conv2.weight: requires_grad=False\n",
      "layer3.4.bn2.weight: requires_grad=False\n",
      "layer3.4.bn2.bias: requires_grad=False\n",
      "layer3.4.conv3.weight: requires_grad=False\n",
      "layer3.4.bn3.weight: requires_grad=False\n",
      "layer3.4.bn3.bias: requires_grad=False\n",
      "layer3.5.conv1.weight: requires_grad=False\n",
      "layer3.5.bn1.weight: requires_grad=False\n",
      "layer3.5.bn1.bias: requires_grad=False\n",
      "layer3.5.conv2.weight: requires_grad=False\n",
      "layer3.5.bn2.weight: requires_grad=False\n",
      "layer3.5.bn2.bias: requires_grad=False\n",
      "layer3.5.conv3.weight: requires_grad=False\n",
      "layer3.5.bn3.weight: requires_grad=False\n",
      "layer3.5.bn3.bias: requires_grad=False\n",
      "layer4.0.conv1.weight: requires_grad=False\n",
      "layer4.0.bn1.weight: requires_grad=False\n",
      "layer4.0.bn1.bias: requires_grad=False\n",
      "layer4.0.conv2.weight: requires_grad=False\n",
      "layer4.0.bn2.weight: requires_grad=False\n",
      "layer4.0.bn2.bias: requires_grad=False\n",
      "layer4.0.conv3.weight: requires_grad=False\n",
      "layer4.0.bn3.weight: requires_grad=False\n",
      "layer4.0.bn3.bias: requires_grad=False\n",
      "layer4.0.downsample.0.weight: requires_grad=False\n",
      "layer4.0.downsample.1.weight: requires_grad=False\n",
      "layer4.0.downsample.1.bias: requires_grad=False\n",
      "layer4.1.conv1.weight: requires_grad=False\n",
      "layer4.1.bn1.weight: requires_grad=False\n",
      "layer4.1.bn1.bias: requires_grad=False\n",
      "layer4.1.conv2.weight: requires_grad=False\n",
      "layer4.1.bn2.weight: requires_grad=False\n",
      "layer4.1.bn2.bias: requires_grad=False\n",
      "layer4.1.conv3.weight: requires_grad=False\n",
      "layer4.1.bn3.weight: requires_grad=False\n",
      "layer4.1.bn3.bias: requires_grad=False\n",
      "layer4.2.conv1.weight: requires_grad=False\n",
      "layer4.2.bn1.weight: requires_grad=False\n",
      "layer4.2.bn1.bias: requires_grad=False\n",
      "layer4.2.conv2.weight: requires_grad=False\n",
      "layer4.2.bn2.weight: requires_grad=False\n",
      "layer4.2.bn2.bias: requires_grad=False\n",
      "layer4.2.conv3.weight: requires_grad=False\n",
      "layer4.2.bn3.weight: requires_grad=False\n",
      "layer4.2.bn3.bias: requires_grad=False\n",
      "fc.weight: requires_grad=True\n",
      "fc.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "# Freeze the feature extractor layers (everything except the final classifier layer)\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Unfreeze the final classifier layer to fine-tune it\n",
    "for param in resnet50.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Print the names of layers and whether they are trainable\n",
    "for name, param in resnet50.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(resnet50.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Reduce lr by 0.5 every 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early stopping criteria\n",
    "# best_accuracy = 0.0\n",
    "# patience = 3  # Stop after 3 epochs with no improvement\n",
    "# epochs_without_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training function\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    # global best_accuracy, epochs_without_improvement\n",
    "    best_accuracy = 0.0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training loop\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        # Calculate train accuracy\n",
    "        train_accuracy = 100 * train_correct / total_train\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        valid_correct = 0\n",
    "        total_valid = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                valid_correct += (preds == labels).sum().item()\n",
    "                total_valid += labels.size(0)\n",
    "                \n",
    "        # Calculate validatin accuracy\n",
    "        valid_accuracy = 100 * valid_correct / total_valid\n",
    "\n",
    "        # Print stats for the epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Validation Accuracy: {valid_accuracy:.2f}%\")\n",
    "\n",
    "        # Save the model with the best validation accuracy\n",
    "        if valid_accuracy > best_accuracy:\n",
    "            best_accuracy = valid_accuracy\n",
    "            torch.save(model.state_dict(), \"best_resnet50_model.pth\")\n",
    "        #     epochs_without_improvement = 0\n",
    "        # else:\n",
    "        #     epochs_without_improvement += 1\n",
    "\n",
    "        # # Save checkpoints after every 5 epochs\n",
    "        # if (epoch + 1) % 5 == 0:\n",
    "        #     torch.save(model.state_dict(), f\"vgg16_epoch_{epoch+1}.pth\")\n",
    "\n",
    "        # # Stop training early if no improvement\n",
    "        # if epochs_without_improvement >= patience:\n",
    "        #     print(\"Early stopping triggered!\")\n",
    "        #     break\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.0054, Train Accuracy: 47.13%, Validation Accuracy: 62.56%\n",
      "Epoch [2/10], Train Loss: 0.8025, Train Accuracy: 62.54%, Validation Accuracy: 62.56%\n",
      "Epoch [3/10], Train Loss: 0.7647, Train Accuracy: 64.70%, Validation Accuracy: 67.79%\n",
      "Epoch [4/10], Train Loss: 0.7207, Train Accuracy: 66.05%, Validation Accuracy: 63.74%\n",
      "Epoch [5/10], Train Loss: 0.7031, Train Accuracy: 66.85%, Validation Accuracy: 66.10%\n",
      "Epoch [6/10], Train Loss: 0.6762, Train Accuracy: 68.58%, Validation Accuracy: 65.43%\n",
      "Epoch [7/10], Train Loss: 0.6654, Train Accuracy: 70.19%, Validation Accuracy: 72.68%\n",
      "Epoch [8/10], Train Loss: 0.6508, Train Accuracy: 70.90%, Validation Accuracy: 71.67%\n",
      "Epoch [9/10], Train Loss: 0.6421, Train Accuracy: 71.75%, Validation Accuracy: 72.18%\n",
      "Epoch [10/10], Train Loss: 0.6598, Train Accuracy: 70.31%, Validation Accuracy: 68.13%\n",
      "Best Validation Accuracy: 72.68%\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "train_model(resnet50, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
